# Day 1

## Invited talks

_Great invited talk:_ Pushmeet Kohli, "Leveraging AI for Science": https://iclr.cc/virtual/2022/invited-talk/7238

_Interesting invited talk:_ Been Kim, "Beyond interpretability: developing a language to shape our relationships with AI": https://iclr.cc/virtual/2022/invited-talk/7237

## Oral 1: AI Applications 

https://iclr.cc/virtual/2022/session/8340

 * Language modeling via stochastic processes
 * Open-Set Recognition: A Good Closed-Set Classifier is All You Need
 * Vision-Based Manipulators Need to Also See from Their Hands

## Oral 1: Learning in the wild, Reinforcement learning

https://iclr.cc/virtual/2022/session/8341

 * Hyperparameter Tuning with Renyi Differential Privacy
 * PiCO: Contrastive Label Disambiguation for Partial Label Learning
 * Poisoning and Backdooring Contrastive Learning
 * Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design
 * The Information Geometry of Unsupervised Reinforcement Learning
 * Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics

## Poster Session 1

https://iclr.cc/virtual/2022/session/8349

 * PF-GNN: Differentiable particle filtering based approximation of universal graph representations
 * Training Structured Neural Networks Through Manifold Identification and Variance Reduction
 * Scale Mixtures of Neural Network Gaussian Processes
 * **Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression**
 * Perceiver IO: A General Architecture for Structured Inputs & Outputs
 * **Topological Graph Neural Networks**
 * **Signing the Supermask: Keep, Hide, Invert**
 * Imbedding Deep Neural Networks
 * Steerable Partial Differential Operators for Equivariant Neural Networks
 * **Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients**
 * **The Three Stages of Learning Dynamics in High-dimensional Kernel Methods**
 * Deconstructing the Inductive Biases of Hamiltonian Neural Networks
 * End-to-End Learning of Probabilistic Hierarchies on Graphs
 * Spanning Tree-based Graph Generation for Molecules
 * 8-bit Optimizers via Block-wise Quantization
 * IntSGD: Adaptive Floatless Compression of Stochastic Gradients
 * **On the Existence of Universal Lottery Tickets**
 * **The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training**
 * Efficient Neural Causal Discovery without Acyclicity Constraints
 * **Learning Synthetic Environments and Reward Networks for Reinforcement Learning**
 * _Variational Neural Cellular Automata_ **THIS ONE**
 * Non-Parallel Text Style Transfer with Self-Parallel Supervision
 * _SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search_ **THIS ONE**
 * Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity
 * Memory Replay with Data Compression for Continual Learning

## Poster Session 2

https://iclr.cc/virtual/2022/session/8350

 * How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis
 * The Spectral Bias of Polynomial Neural Networks
 * A Generalized Weighted Optimization Method for Computational Learning and Inversion
 * Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise
 * Critical Points in Quantum Generative Models
 * Gradient Importance Learning for Incomplete Observations
 * **Learning to Guide and to be Guided in the Architect-Builder Problem**
 * Understanding Intrinsic Robustness Using Label Uncertainty
 * Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks
 * Efficient Self-supervised Vision Transformers for Representation Learning
 * **Fast Model Editing at Scale**
 * **Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface**
 * On Predicting Generalization using GANs
 * Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective
 * **Tackling the Generative Learning Trilemma with Denoising Diffusion GANs**
 * **Illiterate DALL-E Learns to Compose**
 * Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series
 * Salient ImageNet: How to discover spurious features in Deep Learning?
 * A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model
 * Vision-Based Manipulators Need to Also See from Their Hands
 * Chunked Autoregressive GAN for Conditional Waveform Synthesis
 * Quadtree Attention for Vision Transformers
 * **Optimizer Amalgamation**
 * Information-theoretic Online Memory Selection for Continual Learning
 * How Much Can CLIP Benefit Vision-and-Language Tasks?
 * Coordination Among Neural Modules Through a Shared Global Workspace
 * MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC
 * When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations
 * Hierarchical Few-Shot Imitation with Skill Transition Models
 * Spherical Message Passing for 3D Molecular Graphs
 * **Anisotropic Random Feature Regression in High Dimensions**
 * Modular Lifelong Reinforcement Learning via Neural Composition
 * Exploring the Limits of Large Scale Pre-training
 * Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks
 * From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness
 * Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation
 * Continual Learning with Filter Atom Swapping
 * MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer
 * EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression
 * **Peek-a-Boo: What (More) is Disguised in a Randomly Weighted Neural Network, and How to Find It Efficiently** (Sparsity considerations)
 * Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice
 * ...
 

## Poster Session 3




